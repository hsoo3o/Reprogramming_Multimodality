{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_templates = [\n",
    "    'a bad photo of a {}.',\n",
    "    'a photo of many {}.',\n",
    "    'a sculpture of a {}.',\n",
    "    'a photo of the hard to see {}.',\n",
    "    'a low resolution photo of the {}.',\n",
    "    'a rendering of a {}.',\n",
    "    'graffiti of a {}.',\n",
    "    'a bad photo of the {}.',\n",
    "    'a cropped photo of the {}.',\n",
    "    'a tattoo of a {}.',\n",
    "    'the embroidered {}.',\n",
    "    'a photo of a hard to see {}.',\n",
    "    'a bright photo of a {}.',\n",
    "    'a photo of a clean {}.',\n",
    "    'a photo of a dirty {}.',\n",
    "    'a dark photo of the {}.',\n",
    "    'a drawing of a {}.',\n",
    "    'a photo of my {}.',\n",
    "    'the plastic {}.',\n",
    "    'a photo of the cool {}.',\n",
    "    'a close-up photo of a {}.',\n",
    "    'a black and white photo of the {}.',\n",
    "    'a painting of the {}.',\n",
    "    'a painting of a {}.',\n",
    "    'a pixelated photo of the {}.',\n",
    "    'a sculpture of the {}.',\n",
    "    'a bright photo of the {}.',\n",
    "    'a cropped photo of a {}.',\n",
    "    'a plastic {}.',\n",
    "    'a photo of the dirty {}.',\n",
    "    'a jpeg corrupted photo of a {}.',\n",
    "    'a blurry photo of the {}.',\n",
    "    'a photo of the {}.',\n",
    "    'a good photo of the {}.',\n",
    "    'a rendering of the {}.',\n",
    "    'a {} in a video game.',\n",
    "    'a photo of one {}.',\n",
    "    'a doodle of a {}.',\n",
    "    'a close-up photo of the {}.',\n",
    "    'a photo of a {}.',\n",
    "    'the origami {}.',\n",
    "    'the {} in a video game.',\n",
    "    'a sketch of a {}.',\n",
    "    'a doodle of the {}.',\n",
    "    'a origami {}.',\n",
    "    'a low resolution photo of a {}.',\n",
    "    'the toy {}.',\n",
    "    'a rendition of the {}.',\n",
    "    'a photo of the clean {}.',\n",
    "    'a photo of a large {}.',\n",
    "    'a rendition of a {}.',\n",
    "    'a photo of a nice {}.',\n",
    "    'a photo of a weird {}.',\n",
    "    'a blurry photo of a {}.',\n",
    "    'a cartoon {}.',\n",
    "    'art of a {}.',\n",
    "    'a sketch of the {}.',\n",
    "    'a embroidered {}.',\n",
    "    'a pixelated photo of a {}.',\n",
    "    'itap of the {}.',\n",
    "    'a jpeg corrupted photo of the {}.',\n",
    "    'a good photo of a {}.',\n",
    "    'a plushie {}.',\n",
    "    'a photo of the nice {}.',\n",
    "    'a photo of the small {}.',\n",
    "    'a photo of the weird {}.',\n",
    "    'the cartoon {}.',\n",
    "    'art of the {}.',\n",
    "    'a drawing of the {}.',\n",
    "    'a photo of the large {}.',\n",
    "    'a black and white photo of a {}.',\n",
    "    'the plushie {}.',\n",
    "    'a dark photo of a {}.',\n",
    "    'itap of a {}.',\n",
    "    'graffiti of the {}.',\n",
    "    'a toy {}.',\n",
    "    'itap of my {}.',\n",
    "    'a photo of a cool {}.',\n",
    "    'a photo of a small {}.',\n",
    "    'a tattoo of the {}.',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reprogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load('./trained_model/reprogram_trained.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./dataset/audio/audiocaps/train.csv')\n",
    "\n",
    "text_list = list(df['caption'])\n",
    "\n",
    "audio_paths=[\"./dataset/audio/esc50/ESC-50-master/audio/1-17150-A-12.wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "audio_target = load_n_transform_audio_data(audio_paths,device)\n",
    "all_emb = []\n",
    "with torch.no_grad():\n",
    "    tmp_audio_features = model.forward({'audio': audio_target.to(device)})\n",
    "    all_emb.append(tmp_audio_features['audio'])\n",
    "test_audio_features = torch.concat(all_emb)\n",
    "audio_features_norm = test_audio_features / test_audio_features.norm(dim=-1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "bpe_path = './ImageBind/imagebind/bpe/bpe_simple_vocab_16e6.txt.gz'\n",
    "text_prep = load_n_transform_text_data(text_list,bpe_path,device)\n",
    "\n",
    "all_emb = []\n",
    "for i in range(text_prep.shape[0]):\n",
    "    target = text_prep[i:i+10]\n",
    "    with torch.no_grad():\n",
    "        tmp_text_features = model.forward({'text': target.to(device)})\n",
    "        all_emb.append(tmp_text_features['text'])\n",
    "test_text_features = torch.concat(all_emb)\n",
    "text_features_norm = test_text_features / test_text_features.norm(dim=-1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.softmax(audio_features_norm @ text_features_norm.T, dim=-1)\n",
    "\n",
    "sorted_tensor, indices = torch.sort(res, descending=True)\n",
    "np.array(text_list)[indices[:,0:5].cpu()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from preprocessing.sun_rgb_d import *\n",
    "\n",
    "root = './dataset/depth/sun_d/SUNRGBD'\n",
    "\n",
    "gt_classes = get_gt(root)\n",
    "test_depth_path, test_image_path, test_target_list = get_data(root, gt_classes, 'alltest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from preprocessing.preprocessing_utils import *\n",
    "depth_preprocess = get_depth_preprocess()\n",
    "\n",
    "depth_prep = get_preprocessed_depth_data(test_depth_path,depth_preprocess)\n",
    "print('done')\n",
    "all_emb = []\n",
    "for i in range(depth_prep.shape[0]):\n",
    "    target = depth_prep[i:i+10]\n",
    "    with torch.no_grad():\n",
    "        tmp_depth_features = model.forward({'depth': target.to(device)})\n",
    "        all_emb.append(tmp_depth_features['depth'])\n",
    "test_depth_features = torch.concat(all_emb)\n",
    "depth_features_norm = test_depth_features / test_depth_features.norm(dim=-1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "img_name_list = os.listdir('./dataset/image/')\n",
    "img_list = [os.path.join('./dataset/image/', name) for name in img_name_list]\n",
    "\n",
    "image_prep = load_n_transform_image_data(img_list,device)\n",
    "print('done')\n",
    "\n",
    "all_emb = []\n",
    "for i in range(image_prep.shape[0]):\n",
    "    target = image_prep[i:i+1]\n",
    "    with torch.no_grad():\n",
    "        tmp_image_features = model.forward({'image': target.to(device)})\n",
    "        all_emb.append(tmp_image_features['image'])\n",
    "test_image_features = torch.concat(all_emb)\n",
    "image_features_norm = test_image_features / test_image_features.norm(dim=-1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.softmax(audio_features_norm @ depth_features_norm.T, dim=-1)\n",
    "\n",
    "sorted_tensor, indices = torch.sort(res, descending=True)\n",
    "np.array(test_depth_path)[indices[:,0:5].cpu()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reprogram",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
